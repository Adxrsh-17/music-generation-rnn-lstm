{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWiQbmKEzRAQ"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import random\n",
        "import IPython\n",
        "from IPython.display import Image, Audio\n",
        "import music21\n",
        "from music21 import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "%matplotlib inline\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(\"ignore\")\n",
        "import os\n",
        "from music21 import converter\n",
        "import kagglehub\n",
        "np.random.seed(42)\n",
        "from tensorflow import keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeWELqKk0FGC",
        "outputId": "b0db803e-c81c-4436-fa29-cab5ef1d3017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "content_dir = \"classical-music-midi\"\n",
        "\n",
        "if not os.path.exists(content_dir):\n",
        "    os.makedirs(content_dir)  # Create the content directory if it doesn't exist\n",
        "\n",
        "shutil.copytree(path2, content_dir, dirs_exist_ok=True)\n",
        "print(f\"Dataset files moved to: {content_dir}\")\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_wXIo03VrebR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "filepath = os.path.join(content_dir, \"albeniz\")\n",
        "\n",
        "# Initialize a list to store all MIDI streams\n",
        "all_midis = []\n",
        "\n",
        "# Iterate over all files in the Chopin folder and parse MIDI files\n",
        "\n",
        "for filename in os.listdir(filepath):\n",
        "    if filename.endswith(\".mid\"):\n",
        "        midi_path = os.path.join(filepath, filename)\n",
        "        midi = converter.parse(midi_path)\n",
        "        all_midis.append(midi)\n",
        "\n",
        "print(f\"Loaded {len(all_midis)} MIDI files.\")\"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "AUjL7jg8rzi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Corpus = extract_notes(midis)\n",
        "\n",
        "# Function to extract notes and chords from MIDI files\n",
        "\n",
        "def extract_notes(file):\n",
        "    notes = []\n",
        "    pick = None\n",
        "    for j in file:\n",
        "        songs = instrument.partitionByInstrument(j)\n",
        "        for part in songs.parts:\n",
        "            pick = part.recurse()\n",
        "            for element in pick:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return notes\n",
        "\n",
        "\n",
        "print(\"Extracting notes. This may take some time...\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "k5FxBU5vsJdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "# Save the notes as a pickle file\n",
        "notes_pkl_path = os.path.join(\"# PATH \", f\"{composer_name}_notes.pkl\")\n",
        "with open(notes_pkl_path, 'wb') as f:\n",
        "    pickle.dump(Corpus, f)\n",
        "\n",
        "print(f\"Extracted notes saved as {notes_pkl_path}\")\"\"\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Oz66KGqjsgek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "composer_name = \"chopin\""
      ],
      "metadata": {
        "id": "N_pnic4WmOcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidwJuuKzRAS"
      },
      "source": [
        "We have our data in the form of a corpus. A list of strings, if you will. Each string indicates a musical note. Let us explore this data corpus.\n",
        "\n",
        "**In this section**\n",
        "* Exploring the data Corpus\n",
        "* Examine all the notes in the Corpus\n",
        "* Simplifying our Corpus to Built a working model\n",
        "\n",
        "**Have a look at the first 50 values in our corpus**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_notes(file):\n",
        "    notes = []\n",
        "    pick = None\n",
        "    for j in file:\n",
        "        songs = instrument.partitionByInstrument(j)\n",
        "        for part in songs.parts:\n",
        "            pick = part.recurse()\n",
        "            for element in pick:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return notes\n",
        "\n",
        "with open(os.path.join(\"/content/drive/MyDrive/MIDI/\", f\"{composer_name}_MIDI.pkl\"), 'rb') as f:\n",
        "\n",
        "  midi = pickle.load(f)\n",
        "\n",
        "Corpus =   extract_notes(midi)\n",
        "\n",
        "print(\"First fifty values in the Corpus:\", Corpus[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV-SQ2nAZeUd",
        "outputId": "25da077e-1471-445d-9b87-e61f62be1da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First fifty values in the Corpus: ['F3', 'F2', 'G3', 'G2', 'B-3', 'B-2', 'C#4', 'C#3', 'E3', 'E2', 'G3', 'G2', 'F3', 'F2', 'G3', 'G2', 'B-3', 'B-2', 'C#4', 'C#3', 'E3', 'E2', 'G3', 'G2', 'G3', 'G2', 'A3', 'A2', 'C4', 'C3', 'E-4', 'E-3', 'F#3', 'F#2', 'A3', 'A2', 'G3', 'G2', 'A3', 'A2', 'C4', 'C3', 'E-4', 'E-3', 'F#3', 'F#2', 'A3', 'A2', 'B-3', 'B-2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLHaq1xyzRAU",
        "outputId": "f47512f6-da7d-4f3f-ef82-811198d94fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique notes in the Corpus: 397\n"
          ]
        }
      ],
      "source": [
        "#Creating a count dictionary\n",
        "count_num = Counter(Corpus)\n",
        "print(\"Total unique notes in the Corpus:\", len(count_num))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsLRj3qxzRAU"
      },
      "source": [
        "**Examine all the notes in the Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvUBOmUnzRAV",
        "outputId": "7b9a2935-553f-4975-e1e7-e3b978415e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of notes that occur less than 100 times: 270\n",
            "Length of Corpus after elemination the rare notes: 53745\n"
          ]
        }
      ],
      "source": [
        "#Getting a list of rare chords\n",
        "rare_note = []\n",
        "for index, (key, value) in enumerate(count_num.items()):\n",
        "    if value < 100:\n",
        "        m =  key\n",
        "        rare_note.append(m)\n",
        "print(\"Total number of notes that occur less than 100 times:\", len(rare_note))\n",
        "for element in Corpus:\n",
        "    if element in rare_note:\n",
        "        Corpus.remove(element)\n",
        "\n",
        "print(\"Length of Corpus after elemination the rare notes:\", len(Corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa8265YVzRAW",
        "outputId": "26282768-5940-413a-e526-002c10b2247d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 53745\n",
            "Number of unique characters: 255\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty dictionary to store unique characters\n",
        "unique_chars = {}\n",
        "\n",
        "# Iterate through the corpus to collect unique characters\n",
        "for char in Corpus:\n",
        "    if char not in unique_chars:\n",
        "        unique_chars[char] = None\n",
        "\n",
        "# Convert the unique characters to a sorted list\n",
        "symb = sorted(unique_chars.keys())\n",
        "\n",
        "# Lengths of the corpus and unique characters\n",
        "L_corpus = len(Corpus)  # Total number of characters in the corpus\n",
        "L_symb = len(symb)      # Number of unique characters\n",
        "\n",
        "# Build mapping dictionaries\n",
        "mapping = {char: idx for idx, char in enumerate(symb)}\n",
        "reverse_mapping = {idx: char for idx, char in enumerate(symb)}\n",
        "\n",
        "# Print the results\n",
        "print(\"Total number of characters:\", L_corpus)\n",
        "print(\"Number of unique characters:\", L_symb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyFwWLD2zRAX"
      },
      "source": [
        "**Encoding and Splitting the Corpus as Labels and Targets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6JBboIRzRAX",
        "outputId": "16adea4d-4873-4692-fe97-185a39bafaf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of sequences in the Corpus: 53705\n"
          ]
        }
      ],
      "source": [
        "#Splitting the Corpus in equal length of strings and output target\n",
        "length = 40\n",
        "features = []\n",
        "targets = []\n",
        "for i in range(0, L_corpus - length, 1):\n",
        "    feature = Corpus[i:i + length]\n",
        "    target = Corpus[i + length]\n",
        "    features.append([mapping[j] for j in feature])\n",
        "    targets.append(mapping[target])\n",
        "\n",
        "\n",
        "L_datapoints = len(targets)\n",
        "print(\"Total number of sequences in the Corpus:\", L_datapoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DdI3DCtzRAX"
      },
      "outputs": [],
      "source": [
        "# reshape X and normalize\n",
        "X = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n",
        "# one hot encode the output variable\n",
        "y = tensorflow.keras.utils.to_categorical(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "opt = Adamax(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "#Model's Summary\n",
        "model.summary()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "R-ZKsqLWtKFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "X_train, X_seed, y_train, y_seed = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200)\n",
        "model.save(\"model_path\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9icRgdLTtky1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Vk2VMXzRAT"
      },
      "outputs": [],
      "source": [
        "#First Lets write some functions that we need to look into the data\n",
        "\n",
        "def chords_n_notes(Snippet):\n",
        "    Melody = []\n",
        "    offset = 0 #Incremental\n",
        "    for i in Snippet:\n",
        "        #If it is chord\n",
        "        if (\".\" in i or i.isdigit()):\n",
        "            chord_notes = i.split(\".\") #Seperating the notes in chord\n",
        "            notes = []\n",
        "            for j in chord_notes:\n",
        "                inst_note=int(j)\n",
        "                note_snip = note.Note(inst_note)\n",
        "                notes.append(note_snip)\n",
        "                chord_snip = chord.Chord(notes)\n",
        "                chord_snip.offset = offset\n",
        "                Melody.append(chord_snip)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            note_snip = note.Note(i)\n",
        "            note_snip.offset = offset\n",
        "            Melody.append(note_snip)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    Melody_midi = stream.Stream(Melody)\n",
        "    return Melody_midi\n",
        "\n",
        "Melody_Snippet = chords_n_notes(Corpus[:100])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV8orFafzRAZ"
      },
      "source": [
        "**Generating the Melody**\n",
        "\n",
        "A function to obtain the generated music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxVUOqfizRAZ"
      },
      "outputs": [],
      "source": [
        "def Malody_Generator(Note_Count,composer_name):\n",
        "    mdl_dir = '/content/drive/MyDrive/MIDI/Model'  # Update this path if needed\n",
        "    mdl_filename = f\"{composer_name}.keras\"\n",
        "    model_path = os.path.join(mdl_dir, mdl_filename)\n",
        "    model = load_model(model_path)\n",
        "    X_train, X_seed, y_train, y_seed = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    seed = X_seed[np.random.randint(0,len(X_seed)-1)]\n",
        "    Music = \"\"\n",
        "    Notes_Generated=[]\n",
        "    for i in range(Note_Count):\n",
        "        seed = seed.reshape(1,length,1)\n",
        "        prediction = model.predict(seed, verbose=0)[0]\n",
        "        prediction = np.log(prediction) / 1.5 #diversity\n",
        "        exp_preds = np.exp(prediction)\n",
        "        prediction = exp_preds / np.sum(exp_preds)\n",
        "        index = np.argmax(prediction)\n",
        "        index_N = index/ float(L_symb)\n",
        "        Notes_Generated.append(index)\n",
        "        Music = [\n",
        "            reverse_mapping[char] if char in reverse_mapping else random.choice(list(reverse_mapping.values()))\n",
        "            for char in Notes_Generated\n",
        "        ]\n",
        "\n",
        "        seed = np.insert(seed[0],len(seed[0]),index_N)\n",
        "        seed = seed[1:]\n",
        "    #Now, we have music in form or a list of chords and notes and we want to be a midi file.\n",
        "    Melody = chords_n_notes(Music)\n",
        "    Melody_midi = stream.Stream(Melody)\n",
        "    return Music,Melody_midi\n",
        "\n",
        "\n",
        "#getting the Notes and Melody created by the model\n",
        "Music_notes, Melody = Malody_Generator(100,composer_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Melody.write('midi','Melody_Generated.mid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hkk22wsTne-5",
        "outputId": "3c7f11dd-a883-4549-e442-a65bbdf2064a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Melody_Generated.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}