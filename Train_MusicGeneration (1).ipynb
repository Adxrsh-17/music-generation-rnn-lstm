{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y14aKqZ0Jaan"
      },
      "source": [
        "# 1.Data Set & Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH_erg9hdNUs"
      },
      "outputs": [],
      "source": [
        "#Libraries\n",
        "#FOR Model Training\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "#Data Processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from music21 import converter, stream, note, chord\n",
        "\n",
        "\n",
        "import random\n",
        "from collections import Counter\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EI8BFA6OgF9",
        "outputId": "16c97876-7626-4b12-8eb3-ca720b4f772c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/soumikrakshit/classical-music-midi?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.33M/2.33M [00:00<00:00, 112MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /content/dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "# Download the latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"soumikrakshit/classical-music-midi\")\n",
        "\n",
        "# Move the dataset to the Colab root directory\n",
        "shutil.move(path, \"/content/dataset\")\n",
        "print(\"Path to dataset files:\", \"/content/dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qsTUynRBdsU_"
      },
      "outputs": [],
      "source": [
        "composer_name = \"debussy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUWZQzh3JAfx"
      },
      "outputs": [],
      "source": [
        "#Loading the list of chopin's midi files as stream\n",
        "filepath = os.path.join(\"/content/dataset/\", f\"{composer_name}\")\n",
        "#Getting midi files\n",
        "all_midis= []\n",
        "for i in os.listdir(filepath):\n",
        "    if i.endswith(\".mid\"):\n",
        "        tr = filepath+i\n",
        "        midi = converter.parse(tr)\n",
        "        all_midis.append(midi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oPMQ7nkdNUt",
        "outputId": "3d51cc19-51eb-408d-b4cb-ad67d8c27da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total notes in all the Chopin midis in the dataset: 7551\n"
          ]
        }
      ],
      "source": [
        "#Helping function\n",
        "def extract_notes(file):\n",
        "    notes = []\n",
        "    pick = None\n",
        "    for j in file:\n",
        "        songs = instrument.partitionByInstrument(j)\n",
        "        for part in songs.parts:\n",
        "            pick = part.recurse()\n",
        "            for element in pick:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return notes\n",
        "#Getting the list of notes as Corpus\n",
        "Corpus= extract_notes(midi)\n",
        "print(\"Total notes in all the Chopin midis in the dataset:\", len(Corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-rgBkTydNUv",
        "outputId": "0dffdcf8-05b8-423c-9b48-0549f4699869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique notes in the Corpus: 235\n"
          ]
        }
      ],
      "source": [
        "#Creating a count dictionary\n",
        "count_num = Counter(Corpus)\n",
        "print(\"Total unique notes in the Corpus:\", len(count_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWEhw3p3dNUw",
        "outputId": "91e63374-2b3b-45cc-fe05-dd3fb438c7d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of notes that occur less than 100 times: 211\n"
          ]
        }
      ],
      "source": [
        "#Getting a list of rare chords\n",
        "rare_note = []\n",
        "for index, (key, value) in enumerate(count_num.items()):\n",
        "    if value < 100:\n",
        "        m =  key\n",
        "        rare_note.append(m)\n",
        "\n",
        "print(\"Total number of notes that occur less than 100 times:\", len(rare_note))\n",
        "\n",
        "#Eleminating the rare notes\n",
        "for element in Corpus:\n",
        "    if element in rare_note:\n",
        "        Corpus.remove(element)\n",
        "\n",
        "print(\"Length of Corpus after elemination the rare notes:\", len(Corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP27cPofyJN-"
      },
      "source": [
        "# 2.LSTM PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxWy1tWGdNUx",
        "outputId": "74acde24-7f21-4543-f108-f13e56c919c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of characters: 5378\n",
            "Number of unique characters: 196\n"
          ]
        }
      ],
      "source": [
        "# Storing all the unique characters present in my corpus to bult a mapping dic.\n",
        "symb = sorted(list(set(Corpus)))\n",
        "\n",
        "L_corpus = len(Corpus) #length of corpus\n",
        "L_symb = len(symb) #length of total unique characters\n",
        "\n",
        "#Building dictionary to access the vocabulary from indices and vice versa\n",
        "mapping = dict((c, i) for i, c in enumerate(symb))\n",
        "reverse_mapping = dict((i, c) for i, c in enumerate(symb))\n",
        "\n",
        "print(\"Total number of characters:\", L_corpus)\n",
        "print(\"Number of unique characters:\", L_symb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGTtzGCMdNUx",
        "outputId": "da1e7f7a-b1be-4a98-b799-e62508d0f433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of sequences in the Corpus: 5338\n"
          ]
        }
      ],
      "source": [
        "#Splitting the Corpus in equal length of strings and output target\n",
        "length = 40\n",
        "features = []\n",
        "targets = []\n",
        "for i in range(0, L_corpus - length, 1):\n",
        "    feature = Corpus[i:i + length]\n",
        "    target = Corpus[i + length]\n",
        "    features.append([mapping[j] for j in feature])\n",
        "    targets.append(mapping[target])\n",
        "\n",
        "\n",
        "L_datapoints = len(targets)\n",
        "print(\"Total number of sequences in the Corpus:\", L_datapoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSyu2UfadNUx"
      },
      "outputs": [],
      "source": [
        "# reshape X and normalize\n",
        "X = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n",
        "# one hot encode the output variable\n",
        "y = tensorflow.keras.utils.to_categorical(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Dr7FJ57dNUx"
      },
      "outputs": [],
      "source": [
        "#Taking out a subset of data to be used as seed\n",
        "# train on 20% of our dataset\n",
        "X_train, X_seed, y_train, y_seed = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsRi1lW8dNUy"
      },
      "outputs": [],
      "source": [
        "\"\"\"LSTM MODEL\"\"\"\n",
        "\n",
        "#Initialising the Model\n",
        "model = Sequential(). #for feedback as an input\n",
        "\n",
        "\n",
        "# 512 - The number of neurons in the LSTM layer.\n",
        "# The number of input sequence, The number of features\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "\n",
        "\n",
        "model.add(Dropout(0.1)) #  sets 10% input units to zero for not overfitting.\n",
        "\n",
        "\n",
        "model.add(LSTM(256)) # Additional LSTM layer , 256 neurons in this layer\n",
        "#reducing complexity as the model progresses deeper.\n",
        "\n",
        "\n",
        "model.add(Dense(256)) # map the LSTM output to a higher-dimensional space for feature extraction\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(y.shape[1], activation='softmax')) # activation function converts raw scores into probabilities\n",
        "\n",
        "#Compiling the model for training\n",
        "opt = Adamax(learning_rate=0.01)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt) # multi-class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cMgSJzodNUy"
      },
      "outputs": [],
      "source": [
        "#Training the Model\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBCRAoiAMtUV"
      },
      "source": [
        "# 3.Melody Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFUUzEyJdNUu"
      },
      "outputs": [],
      "source": [
        "def chords_n_notes(Snippet):\n",
        "    Melody = []\n",
        "    offset = 0 #Incremental\n",
        "    for i in Snippet:\n",
        "        #If it is chord\n",
        "        if (\".\" in i or i.isdigit()):\n",
        "            chord_notes = i.split(\".\") #Seperating the notes in chord\n",
        "            notes = []\n",
        "            for j in chord_notes:\n",
        "                inst_note=int(j)\n",
        "                note_snip = note.Note(inst_note)\n",
        "                notes.append(note_snip)\n",
        "                chord_snip = chord.Chord(notes)\n",
        "                chord_snip.offset = offset\n",
        "                Melody.append(chord_snip)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            note_snip = note.Note(i)\n",
        "            note_snip.offset = offset\n",
        "            Melody.append(note_snip)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    Melody_midi = stream.Stream(Melody)\n",
        "    return Melody_midi\n",
        "\n",
        "Melody_Snippet = chords_n_notes(Corpus[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ0wV6CwdNUz"
      },
      "outputs": [],
      "source": [
        "def Malody_Generator(Note_Count):\n",
        "    mdl_dir = '/content/drive/MyDrive/MIDI/Model'  # Update this path if needed\n",
        "    mdl_filename = f\"{composer_name}.keras\"\n",
        "    model_path = os.path.join(mdl_dir, mdl_filename)\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    seed = X_seed[np.random.randint(0,len(X_seed)-1)]\n",
        "    Music = \"\"\n",
        "    Notes_Generated=[]\n",
        "    for i in range(Note_Count):\n",
        "        seed = seed.reshape(1,length,1)\n",
        "        prediction = model.predict(seed, verbose=0)[0]\n",
        "        prediction = np.log(prediction) / 1.0 #diversity\n",
        "        exp_preds = np.exp(prediction)\n",
        "        prediction = exp_preds / np.sum(exp_preds)\n",
        "        index = np.argmax(prediction)\n",
        "        index_N = index/ float(L_symb)\n",
        "        Notes_Generated.append(index)\n",
        "        Music = [\n",
        "            reverse_mapping[char] if char in reverse_mapping else random.choice(list(reverse_mapping.values()))\n",
        "            for char in Notes_Generated\n",
        "        ]\n",
        "        seed = np.insert(seed[0],len(seed[0]),index_N)\n",
        "        seed = seed[1:]\n",
        "    #Now, we have music in form or a list of chords and notes and we want to be a midi file.\n",
        "    Melody = chords_n_notes(Music)\n",
        "    Melody_midi = stream.Stream(Melody)\n",
        "    return Music,Melody_midi\n",
        "\n",
        "\n",
        "#getting the Notes and Melody created by the model\n",
        "Music_notes, Melody = Malody_Generator(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "j67fINiend4U",
        "outputId": "dfefa822-15ee-4e5a-bcbf-fd235d254508"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Melody_Generated.mid'"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Melody.write('midi','Melody_Generated.mid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utHOsnw_N7KG"
      },
      "source": [
        "# 4.Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrU--kSUN3rz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Extract metrics\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot training vs validation loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 196294,
          "sourceId": 434491,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 1627759,
          "sourceId": 2677541,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30129,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}